Trong phần này, tác giả xem lại các nghiên cứu về học biểu diễn đồ thị liên quan tới mô hình của tác giả. Chúng được chia thành hai phần nhỏ: phần đầu tóm tắt các nỗ lực nghiên cứu về GNN cho việc nhúng đồ thị, phần sau giới thiệu các phương pháp nhúng đồ thị cho các đồ thị không đông nhất.

\subsection{Mạng neuron đồ thị}
Mục tiêu của một GNN là học một biểu diễn vector thấp chiều $\pmb{h}_{\upsilon}$ cho mọi nút $\upsilon$, cách được sử dụng cho nhiều tác vụ downstream, ví dụ như phân loại nút, phân cụm nút và dự đoán liên kết. Lý do đằng sau điều này là mỗi nút được xác định một cách tự nhiên bởi các đặc trưng và khu vực lân cận của nó. Theo ý tưởng này và dựa trên quá trình xử lý tín hiệu đồ thị, GNNs dựa trên phổ được phát triển để thực hiện tích chập đồ thị trong miền Fourier của một đồ thị. ChebNet [8] sử dụng các đa thức Chebusev để lọc các tín hiệu đồ thị (đặc trưng nút) trong miền Fourier của đồ thị. Một mô hình có ảnh hưởng khác thuộc loại này là GCN [16], nó ràng buộc và đơn giản hóa các tham số của ChebNet để giảm bớt vấn đề overfitting và cải thiện hiệu năng. Tuy nhiên, GNNs dựa trên phổ có khả năng mở rộng và tổng quát kém vì chúng yêu cầu toàn bộ đồ thị làm đầu vào cho mọi lớp và các bộ lọc đã được học của chúng phụ thuộc vào cơ sở riêng của Laplacian của đồ thị, liên quan chặt chẽ đến cấu trúc đồ thị cụ thể.