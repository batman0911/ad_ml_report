Trong phần này, chúng tôi trình bày các thực nghiệm để chứng minh tính hiệu quả của MAGNN đối với việc biểu diễn đồ thị không đồng nhất. Các thực nghiệm nhằm giải quyết các câu hỏi nghiên cứu sau:

\begin{itemize}
  \item RQ1. MAGNN có hiệu quả như thế nào trong việc phân loại các nút?
  \item RQ2. MAGNN có hiệu quả như thế nào trong việc phân cụm các nút?
  \item RQ3. MAGNN có hiệu quả như thế nào trong việc dữ đoán các liên kết hợp lí giữa các cặp nút?
  \item RQ4. Ảnh hưởng của 3 thành phần chính của MAGNN đã được mô tả trong các phần trước đó là gì?
  \item RQ5. Làm cách nào để ta có thể xác định được tính đại diện của những phương pháp biểu diễn đồ thị khác nhau?
\end{itemize}

\subsection{Tập dữ liệu}
Chúng tôi lựa chọn 03 tập dữ liệu đồ thị không đồng nhất phổ biến nhất hiện nay từ các lĩnh vực khác nhau để đánh giá hiệu năng của MAGNN khi so sánh với các phương pháp cơ sở là các phương pháp tối ưu nhất hiện nay (baselines). Cụ thể, tập dữ liệu IMDb và DBLP được sử dụng trong thực nghiệm liên quan đến việc phân loại nút và phân cụm nút. Tập dữ liệu Last.fm được sử dụng cho thực nghiệm về khả năng dự báo mối quan hệ. Những giá trị thống kê cơ bản của 03 tập dữ liệu được tóm tắt trong Bảng 2, và mô hình mạng được thể hiện trong Hình 3. Chúng tôi sử dụng vector one-hot cho các nút không có thuộc tính như là các thuộc tính đầu vào giả (dummy) của chúng. 

\begin{itemize}
  \item $\mathbf{IMDb}^{1}$ là cơ sở dữ liệu trực tuyến về các bộ phim và chương trình truyền hình, bao gồm các thông tin như dàn diễn viên, đội ngũ sản xuất và tóm tắt cốt truyện. Chúng tôi sử dụng một tập mẫu được lấy ra từ IMDb, thông qua quá trình tiền xử lí dữ liệu thu được 4278 bộ phim, 2081 đạo diễn và 5257 diễn viên. Phim được gắn nhãn là một trong ba loại (Hành động, Hài kịch và Chính kịch) dựa trên thông tin thể loại của chúng. Mỗi bộ phim cũng được mô tả bằng một bag-of-words đại diện cho các từ khóa cốt truyện của chúng. Đối với các mô hình học bán giám sát, các nút phim được chia thành các tập huấn luyện, xác thực và kiểm tra với kích thước lần lượt là 400 (9,35\%), 400 (9,35\%) và $3478(81,30 \%)$ nút.
  \item $\mathbf{DBLPP}^{2}$ là một trang web tổng hợp danh mục tài liệu về khoa học máy tính. Chúng tôi sử dụng một tập mẫu được lấy ra từ DBLP [12, 15], sau khi tiền xử lí dữ liệu thu được thông tin về 4057 tác giả, 14328 bài báo, 7723 thuật ngữ và 20 nơi xuất bản. Các tác giả được chia thành bốn lĩnh vực nghiên cứu (Cơ sở dữ liệu, Khai thác dữ liệu, Trí tuệ nhân tạo và Truy xuất thông tin). Mỗi tác giả được mô tả bằng một bag-of-words đại diện cho các từ khóa trong bài báo của họ. Đối với các mô hình học bán giám sát, các nút tác giả được chia thành các tập huấn luyện, xác thực và kiểm tra với kích thước lần lượt là $400(9,86 \%)$ 400 (9,86\%) và 3257 (80,28\%) nút.
  \item $\mathbf{Last.fm}^{3}$ là trang web âm nhạc theo dõi thông tin hành vi nghe nhạc của người dùng từ nhiều nguồn khác nhau. Chúng tôi sử dụng bộ dữ liệu do HetRec 2011 phát hành [4], sau khi tiền xử lí dữ liệu thu được thông tin về 1892 người dùng, 17632 nghệ sĩ và 1088 thẻ nghệ sĩ. Tập dữ liệu này được sử dụng cho tác vụ dự đoán liên kết giữa các nút, trong đó tập dữ liệu không chưa bất cứ thông tin nào liên quan đến nhãn hay các đặc điểm đặc trưng của đối tượng. Đối với các mô hình học bán giám sát, các cặp người dùng-nghệ sĩ được chia thành các tập huấn luyện, xác thực và kiểm tra với kích thước lần lượt là $64984(70 \%), 9283(10 \%)$ và $18567(20 \%)$ cặp.
\end{itemize}

\subsection{Mô hình cơ sở để tham chiếu}
Chúng tôi so sánh MAGNN với nhiều loại mô hình biểu diễn đồ thị khác nhau, bao gồm các mô hình biểu diễn đồ thị đồng nhất truyền thống (trái ngược với GNN), mô hình biểu diễn đồ thị không đồng nhất truyền thống, GNN cho đồ thị đồng nhất và GNN cho đồ thị không đồng nhất. Ta gọi chúng lần lượt là mô hình đồng nhất truyền thống, mô hình không đồng nhất truyền thống, GNN đồng nhất và GNN không đồng nhất. Danh sách các mô hình cơ sở được thể hiện dưới đây.

\begin{itemize}
  \item $\mathbf{LINE}$ [25] là một mô hình đồng nhất truyền thống khai thác mức độ tương đồng bậc nhất và bậc hai giữa các nút. Chúng tôi áp dụng mô hình này cho các đồ thị không đồng nhất bằng cách bỏ qua tính không đồng nhất của cấu trúc đồ thị và loại bỏ tất cả các thuộc tính liên quan đến nội dung nút. Trong các thử nghiệm của tác giả, chúng tôi sử dụng biến thể LINE sử dụng mức độ tương đồng bậc hai.
  \item $\mathbf{node2vec}$ [13] là một mô hình đồng nhất truyền thống và có thể coi là phiên bản tổng quát của DeepWalk [21]. Chúng tôi áp dụng mô hình này cho các đồ thị không đồng nhất theo cách tương tự như LINE.
  \item $\mathbf{ESim}$ [22] là một mô hình không đồng nhất truyền thống học cách biểu diễn nút từ các cấu hình metapath đã được lấy mẫu. ESim yêu cầu xác định trước các trọng số cho mỗi metapath. Ở đây, chúng tôi chỉ định các trọng số bằng nhau cho tất cả các metapath vì việc tìm kiếm  các trọng số tối ưu của các metapath là rất khó và không mang lại mức tăng hiệu suất đáng kể so với các trọng số mặc định bằng nhau theo các thử nghiệm của nhóm tác giả.
  \item $\mathbf{metapath2vec}$ [9] là một mô hình không đồng nhất truyền thống tạo ra các biểu diễn nút bằng cách cung cấp các random walks được định hướng bởi metapath cho một mô hình skip-gram. Mô hình này dựa trên một metapath do người dùng chỉ định, vì vậy chúng tôi thử nghiệm trên tất cả các metapath riêng biệt và tổng kết metapath có kết quả tốt nhất. Chúng tôi sử dụng biến thể metapath2vec++ trong các thử nghiệm của mình. 
  \item $\mathbf{HERec}$ [23] là một mô hình không đồng nhất truyền thống học cách biểu diễn nút bằng cách áp dụng DeepWalk cho các đồ thị đồng nhất dựa trên metapath được chuyển đổi từ đồ thị không đồng nhất ban đầu. Mô hình này đi kèm với một thuật toán kết hợp biểu diễn được thiết kế để dự đoán xếp hạng, có thể được điều chỉnh để dự đoán liên kết. Để phân loại/phân cụm nút, chúng tôi chọn và báo cáo kết quả cho metapath có hiệu suất tốt nhất.
  \item $\mathbf{GCN}$ [16] là một mô hình GNN đồng nhất. Mô hình này thực hiện các phép toán tích chập trong miền Fourier của đồ thị. Ở đây, chúng tôi kiểm tra hiệu suất của GCN trên các đồ thị đồng nhất dựa trên metapath và báo cáo kết quả cho metapath tốt nhất.
  \item $\mathbf{GAT}$ [28] là một GNN đồng nhất. Mô hình này thực hiện các thao tác tích chập trong miền không gian đồ thị với cơ chế kết hợp có chú ý. Tương tự, ở đây chúng tôi kiểm tra GAT trên các đồ thị đồng nhất dựa trên metapath và báo cáo kết quả cho metapath tốt nhất.
  \item $\mathbf{GATNE}$ [5] là một GNN không đồng nhất. Mô hình này tạo ra biểu diễn của nút từ biểu diễn cơ sở và biểu diễn cạnh, tập trung vào nhiệm vụ dự đoán liên kết. Ở đây chúng tôi báo cáo kết quả từ biến thể GATNE có hiệu quả tốt nhất.
  \item $\mathbf{HAN}$ [31] là một GNN không đồng nhất. Mô hình này học cách biểu diễn nút với metapath cụ thể từ các đồ thị đồng nhất khác nhau dựa trên metapath và tận dụng cơ chế chú ý để kết hợp chúng thành một biểu diễn vectơ cho mỗi nút.
\end{itemize}

Đối với các mô hình truyền thống, bao gồm LINE, node2vec, ESim, metapath2vec và HERec, chúng tôi thiết lập window size là 5, walk length là 100, số bước đi trên mỗi nút là 40 và số lượng mẫu âm tính là 5 (nếu có). Đối với các mô hình GNN (bao gồm GCN, GAT, HAN và MAGNN), chúng tôi đặt tỷ lệ dropout là 0,5; chúng tôi sử dụng tập dữ liệu huấn luyện, xác thực và kiểm tra có kích thước bằng nhau; chúng tôi sử dụng phương pháp Adam cho các nhiệm vụ tối ưu hóa với learning rate được thiết lập là 0,005 và tham số phân rã (L2) được đặt là 0,001; chúng tôi huấn luyện mô hình GNN trong 100 epochs và cho phép dừng sớm với ngưỡng patience là 30. Để phân loại nút và phân cụm nút, GNN được huấn luyện theo kiểu bán giám sát với một phần nhỏ các nút được gắn nhãn. Đối với GAT, HAN và MAGNN, chúng tôi thiết lập số lượng head chú ý là 8. Đối với HAN và MAGNN, chúng tôi thiết lập số chiều (thứ nguyên) của vectơ chú ý trong tập hợp giữa các metapath là 128. Để việc so sánh được công bằng, chúng tôi đặt số chiều (thứ nguyên) biểu diễn của tất cả các mô hình được đề cập ở trên đến 64.

\subsection{Phân loại nút (RQ1)}
Chúng tôi tiến hành thử nghiệm trên  tập dữ liệu IMDb và DBLP để so sánh hiệu năng của các mô hình khác nhau đối với tác vụ phân loại nút. Chúng tôi cung cấp biểu diễn của các nút được gắn nhãn (phim trong IMDb và tác giả trong DBLP) được tạo ra bởi mỗi mô hình cho bộ phân loại máy vectơ hỗ trợ tuyến tính (SVM) với các tỷ lệ đào tạo khác nhau. Lưu ý rằng để so sánh công bằng, chỉ các nút trong tập thử nghiệm được đưa vào SVM tuyến tính, bởi vì các mô hình bán giám sát đã "nhìn thấy" các nút trong tập huấn luyện và xác nhận, như được hiển thị trong Phương trình 11. Do đó, việc đào tạo và tỷ lệ thử nghiệm của SVM tuyến tính ở đây chỉ liên quan đến bộ thử nghiệm (nghĩa là 3478 nút cho IMDb và 3257 nút cho DBLP). Một lần nữa, các phân tách đào tạo/kiểm tra cho SVM tuyến tính cũng giống nhau trên các mô hình nhúng. Các chiến lược tương tự cũng được áp dụng cho các thí nghiệm về phân cụm nút và dự đoán liên kết. Chúng tôi báo cáo Macro-F1 và Micro-F1 trung bình của 10 lần chạy của từng mô hình nhúng trong Bảng 3.

We conduct experiments on the IMDb and DBLP datasets to compare the performance of different models on the node classification task. We feed the embeddings of labeled nodes (movies in IMDb and authors in DBLP) generated by each learning model to a linear support vector machine (SVM) classifier with varying training proportions. Note that for a fair comparison, only the nodes in the testing set are fed to the linear SVM, because semi-supervised models have already "seen" the nodes in the training and validation sets, as shown in Equation 11. Hence, the training and testing proportions of the linear SVM here only concern the testing set (i.e., 3478 nodes for IMDb and 3257 nodes for DBLP). Again, the train/test splits for the linear SVM are also the same across embedding models. Similar strategies are also applied to the experiments of node clustering and link prediction. We report the average Macro-F1 and Micro-F1 of 10 runs of each embedding model in Table 3.

As shown in the table, MAGNN performs consistently better than other baselines across different training proportions and datasets. On IMDb, it is interesting to see that node2vec performs better than traditional heterogeneous models. That said, GNNs, especially heterogeneous GNNs, obtain even better results, demonstrating that the GNN architecture, which judiciously utilizes the heterogeneous node features, helps improve the embedding performance. The performance gain obtained by MAGNN over the best baseline (HAN) is around 4-7\%, which indicates that metapath instances contain richer information than metapath-based neighbors. On DBLP, the node classification task is trivial, as evident from the high scores of all models. Even so, MAGNN still outperforms the strongest baseline by $1-2 \%$. 
