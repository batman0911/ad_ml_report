Nhiều bộ dữ liệu thực tế được biểu diễn với cấu trúc dữ liệu đồ thị, trong đó các đối tượng và quan hệ giữa chúng được biểu diễn bằng các nút và cạnh. Các ví dụ bao gồm mạng xã hội [14, 29], hệ thống vật lý [2, 10], mạng giao thông [18, 34], mạng trích dẫn [1, 14, 16], hệ thống gợi ý [26, 35], đồ thị tri thức [3, 24], ... Bản chất non-Euclidean của đồ thị khiến chúng khó được mô hình hóa bằng các mô hình học máy truyền thống. Với tập lân cận của mỗi nút, không hề có thứ tự hoặc giới hạn về kích thước, Tuy nhiên, hầu hết các mô hình thống kê giả định rằng một đầu vào có thứ tự và kích thước cố định trong không gian Euclid. Do đó, sẽ thuận tiện nếu các nút có thể được biểu diễn bằng các vector thấp chiều trong không gian Euclid và từ đó có thể lấy làm đầu vào của mô hình học máy khác. 

Các kĩ thuật embed đồ thị khác nhau được đề xuất cho cấu trúc dữ liệu đồ thị. LINE [25] sinh node embedding dựa vào các nút gần nhất và gần thứ 2. Các phương pháp dựa trên bước ngẫu nhiên (Random-walk) bao gồm DeepWalk [21], node2vec [13] và TADW [32] sinh dãy nút được sinh ra bởi các bước ngẫu nhiên đến một mô hình skip-gram [19] để học node embeddings. Với sự phát triển nhanh chóng của deep learning, mạng neuron đồ thị (Graph neural networks - GNNs) được đề xuất, mô hình học các biểu diễn đồ thị bằng việc sử dụng các lớp neuron được thiết kế đặc biệt. Spectral-based GNNs bao gồm ChebNet [8] và GCN [16] biểu diễn các toán tử tích chập đồ thị trong miền Fourier của một đồ thị đầy đủ. Các mô hình dựa trên spatial, bao gồm GraphSAGE [14], GAT [28] và nhiều biến thể khác [17, 34, 45], giải quyết các vấn đề xung quanh khả năng mở rộng và khả năng tổng quát hóa của các mô hình dựa trên phổ bằng cách biểu diễn các phép toán tích chập đồ thị trực tiếp trên miền đồ thị. 

Mặc dù GNNs đã đạt được những kết quả tốt nhất trong nhiều bài toán, hầu hết các mô hình dựa trên GNN giả định rằng đầu vào là đồ thị đồng nhất với chỉ một loại nút và một loại cạnh. Hầu hết đồ thị trong thực tế bao gồm nhiều loại nút và cạnh tương ứng với các thuộc tính trong các không gian thuộc tính khác nhau. Ví dụ, một mạng đồng tác giả chứa ít nhất hai loại nút, cụ thể là các tác giả và bài báo. Các thuộc tính của tác giả có thể bao gồm nơi làm việc, trích dẫn và lĩnh vực nghiên cứu. Thuộc tính của bài báo bao gồm từ khóa, địa điểm, năm phát hành ... Tác giả gọi loại đồ thị này là \textit{mạng thông tin không đồng nhất} (HINs) hoặc \textit{đồ thị không đồng nhất.}
 Sự không đồng nhất trong cả cấu trúc biểu diễn và nội dung của nút khiến GNN gặp khó khăn trong việc mã hóa thông tin vào không gian vector thấp chiều. 

 Hầu hết các phương pháp nhúng đồ thị không đồng nhất hiện có dựa trên ý tưởng về metapaths. Một \textit{metapath} là một trình tự có thứ tự của các loại nút và loại cạnh được xác định trên lược đồ mạng, mô tả mối quan hệ tổng hợp giữa các loại nút liên quan. Ví dụ một mạng với tác giả, bài báo và dịa điểm, \textit{Tác giả-Bài báo-Tác giả} (APA) và \textit{Tác giả-Bài báo-Địa điểm-Bài báo-Tác giả} (APVPA) là các metapaths mô tả mối quan hệ khác nhau giữa các tác giả. Metapath APA tương ứng với hai đồng tác giả, trong khi APVPA tương ứng với hai tác giả xuất bản bài báo cùng địa điểm. Do đó, ta có thể xem metapath là khoảng cách gần bậc cao giữa 2 nút. Do GNNs truyền thống xử lý tất cả các nút như nhau, chúng không thể mô hình hóa cấu trúc phức tạp và thông tin có nghĩa trong đồ thị không đồng nhất.


 Mặc dù các phương pháp nhúng dựa trên metapath này hoạt động tốt hơn phương pháp nhúng mạng truyền thống trên các bài toán khác nhau, chẳng hạn như phân loại nút và dự đoán liên kết, chúng vẫn có ít nhất một trong những hạn chế sau. (1) Mô hình không sử dụng đặc trưng về nội dung nút nên nó hiếm khi hoạt động tốt với các đồ thị không đồng nhất với nút có nội dung nhiều đặc trưng (ví dụ metapath2vec [9], ESim [22], HIN2vec [11], HERec [23]). (2) Mô hình loại bỏ tất cả các nút trên metapath, chỉ xem xét 2 nút cuối dẫn đến mất thông tin (ví dụ HERec [23] and HAN [31]). (3) Mô hình dựa trên một metapath duy nhất để nhúng đồ thị không đồng nhất. Do đó, mô hình yêu cầu một quá trình chọn metapath thủ công và mất đi các đặc điểm của thông tin từ các metapaths khác dẫn đến hiệu năng không tối ưu (ví dụ metapath2vec [9]). 

 Để giải quyết các hạn chế này, tác giả đề xuất một mạng neuron tổng hợp metapath (\textit{Metapath Aggregated Graph Neural Network - MAGNN}) mới cho việc nhúng đồ thị không đồng nhất. MAGNN giải quyết tất cả các vấn đề được mô tả ở trên bằng cách áp dụng chuyển đổi nội dung nút, tổng hợp nội intra-metapath và tổng hợp inter-metapath để tạo nút nhúng. Cụ thể, MAGNN trước tiên áp dụng biến đổi tuyến tính theo loại cụ thể để chiếu các thuộc tính nút không đồng nhất với số chiều có thể không bằng nhau cho các loại nút khác nhau, cho cùng một không gian latent. Tiếp theo, MAGNN áp dụng intra-metapath với cơ chế chú ý [28] cho mọi metapath. Trong tổng hợp intra-metapath này, mỗi nút đích trích xuất và kết hợp thông tin từ các cấu hình metapath kết nối với nút lân cận dựa trên metapath của nó. Bằng cách này, MAGNN nắm bắt được thông tin về cấu trúc và ngữ nghĩa của các đồ thị không đồng nhất từ cả các nút lân cận và bối cảnh metapath giữa chúng. Sau khi tổng hợp intra-metapath, MAGNN tiếp tục tiến hành tổng hợp inter-metapath bằng cách sử dụng cơ chế chú ý để hợp nhất các latent vector thu được từ nhiều metapaths vào các nút nhúng cuối cùng. Bằng cách tích hợp nhiều metapaths, mô hình của tác giả có thể học ngữ nghĩa toàn diện ẩn giấu trong đồ thị không đồng nhất. 

Tóm lại, bài báo này có một số đóng góp chính:
\begin{itemize}
  \item[] (1) Tác giả đề xuất một mạng neuron đồ thị mới  dựa trên tổng hợp metapath để nhúng nhúng đồ thị không đồng nhất.
  \item[] (2) Thiết kế một số hàm mã hóa tiềm năng để trích xuất thông tin từ các cấu hình metapaths, bao gồm trường hợp dựa trên ý tưởng phép xoay quan hệ trong không gian phức [24].
  \item[] (3) Tác giả tiến hành nhiều thí nghiệm trên các tập dữ liệu IMDb và DBLP để phân loại và phân cụm nút cũng như dùng tập Last.fm để đánh giá dự đoán liên kết và hiệu suất của mô hình. Thí nghiệm trên tất cả các tập dữ liệu này và các bài toán chỉ ra rằng nhúng nút được học bởi MAGNN luôn tốt hơn các mô hình tiên tiến nhất hiện tại (SOTA).
\end{itemize}

\begin{table}[]
  \label{tb:01}
  \caption[]{Kí hiệu được dùng trong báo cáo}
  \begin{tabular}{ll}
  \hline
  \multicolumn{1}{|l|}{Kí hiệu} & \multicolumn{1}{l|}{Định nghĩa} \\ \hline
  \multicolumn{1}{|l|}{$\mathbb{R}^n$} & \multicolumn{1}{l|}{Không gian vector Euclid $n$ chiều} \\ \hline
  \multicolumn{1}{|l|}{$a, \mathbf{a}, \mathbf{A}$} & \multicolumn{1}{l|}{Số, vector, ma trận}   \\ \hline
  \multicolumn{1}{|l|}{$\mathbf{A}^T$} & \multicolumn{1}{l|}{Ma trận/vector chuyển vị}   \\ \hline
  \multicolumn{1}{|l|}{$\pmb{\mathcal{V}}$} & \multicolumn{1}{l|}{Tập đỉnh của đồ thị}   \\ \hline
  \multicolumn{1}{|l|}{$\pmb{\mathcal{E}}$} & \multicolumn{1}{l|}{Tập cạnh của đồ thị}   \\ \hline
  \multicolumn{1}{|l|}{$\pmb{\mathcal{G}}$} & \multicolumn{1}{l|}{Đồ thị $\pmb{\mathcal{G} = (\pmb{\mathcal{V}}, \pmb{\mathcal{E}})}$}   \\ \hline
  \multicolumn{1}{|l|}{$\nu$} & \multicolumn{1}{l|}{Một nút $\nu \in \pmb{\mathcal{V}}$}   \\ \hline
  \multicolumn{1}{|l|}{$P$} & \multicolumn{1}{l|}{Một metapath}   \\ \hline
  \multicolumn{1}{|l|}{$P{\nu, u}$} & \multicolumn{1}{l|}{Một cấu hình metapath kết nối nút $\nu$ và nút $u$}   \\ \hline
  \multicolumn{1}{|l|}{$\pmb{\mathcal{N}}_{\nu}$} & \multicolumn{1}{l|}{Tập lân cận của nút $\nu$}   \\ \hline
  \multicolumn{1}{|l|}{$\pmb{\mathcal{N}}^P_{\nu}$} & \multicolumn{1}{l|}{Tập lân cận dựa trên metapath $P$ của nút $\nu$}   \\ \hline
  \multicolumn{1}{|l|}{$x_{\nu}$} & \multicolumn{1}{l|}{Đặc trưng (nội dung) thô của nút $\nu$}   \\ \hline
  \multicolumn{1}{|l|}{$h_{\nu}$} & \multicolumn{1}{l|}{Trạng thái ẩn (nhúng) của nút $\nu$}   \\ \hline
  \multicolumn{1}{|l|}{$\mathbf{W}$} & \multicolumn{1}{l|}{Ma trận trọng số}   \\ \hline
  \multicolumn{1}{|l|}{$\alpha, \beta$} & \multicolumn{1}{l|}{Trọng số chú ý chuẩn hóa}   \\ \hline
  \multicolumn{1}{|l|}{$\sigma (\cdot)$} & \multicolumn{1}{l|}{Hàm kích hoạt}   \\ \hline
  \multicolumn{1}{|l|}{$\bigodot$} & \multicolumn{1}{l|}{Phép nhân phần tử}   \\ \hline
  \multicolumn{1}{|l|}{$|\cdot|$} & \multicolumn{1}{l|}{Lực lượng của tập hợp}   \\ \hline
  \multicolumn{1}{|l|}{$\parallel$} & \multicolumn{1}{l|}{Nối vector}   \\ \hline
                                &                                
  \end{tabular}
  \end{table}